"""
Model Card Generator Module
==========================

ëª¨ë¸ì¹´ë“œ ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆ
"""

import os
import logging
from typing import Optional

logger = logging.getLogger(__name__)


class ModelCardGenerator:
    """ëª¨ë¸ì¹´ë“œ ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ModelCardGenerator ì´ˆê¸°í™”"""
        pass
    
    def create_model_card(self, model_path: str, repo_name: str) -> str:
        """
        í•œêµ­ì–´ ëª¨ë¸ì¹´ë“œ ìƒì„± (ì›ë³¸ í•¨ìˆ˜ ë‚´ìš© ë³´ì¡´)
        
        Args:
            model_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
            repo_name: ë¦¬í¬ì§€í† ë¦¬ ì´ë¦„
            
        Returns:
            ìƒì„±ëœ README.md íŒŒì¼ ê²½ë¡œ
        """
        logger.info(f"ëª¨ë¸ì¹´ë“œ ìƒì„± ì‹œì‘: {repo_name}")
        
        # ì›ë³¸ README ë‚´ìš© ê·¸ëŒ€ë¡œ ë³´ì¡´
        readme_content = \
        f"""---
            license: apache-2.0
            base_model: unsloth/gpt-oss-20b
            tags:
            - unsloth
            - lora
            - korean
            - education
            - textbook
            - gpt-oss
            - í•œêµ­ì–´
            - êµìœ¡
            - íŒŒì¸íŠœë‹
            language:
            - ko
            datasets:
            - maywell/korean_textbooks
            library_name: peft
            pipeline_tag: text-generation
            ---
            
            # í•œêµ­ì–´ êµìœ¡ ìë£Œ íŒŒì¸íŠœë‹ ëª¨ë¸ (Korean Textbook Fine-tuned Model)
            
            ## ğŸ“š ëª¨ë¸ ì†Œê°œ
            
            ì´ ëª¨ë¸ì€ **unsloth/gpt-oss-20b**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **maywell/korean_textbooks** ë°ì´í„°ì…‹ìœ¼ë¡œ íŒŒì¸íŠœë‹ëœ í•œêµ­ì–´ êµìœ¡ ì „ìš© ëª¨ë¸ì…ë‹ˆë‹¤.
            LoRA(Low-Rank Adaptation) ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµë˜ì—ˆìœ¼ë©°, í•œêµ­ì–´ êµìœ¡ ì½˜í…ì¸  ìƒì„±ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
            
            ## ğŸ¯ ì£¼ìš” íŠ¹ì§•
            
            - **ë² ì´ìŠ¤ ëª¨ë¸**: unsloth/gpt-oss-20b (20B íŒŒë¼ë¯¸í„°)
            - **í›ˆë ¨ ë°©ë²•**: LoRA (Low-Rank Adaptation)
            - **íŠ¹í™” ë¶„ì•¼**: í•œêµ­ì–´ êµìœ¡ ì½˜í…ì¸  ìƒì„±
            - **ë°ì´í„°ì…‹**: maywell/korean_textbooks
            - **ì–¸ì–´**: í•œêµ­ì–´ (Korean)
            
            ## ğŸš€ ì‚¬ìš© ë°©ë²•
            
            ### ëª¨ë¸ ë¡œë“œ
            
            ```python
            from transformers import AutoModelForCausalLM, AutoTokenizer
            from peft import PeftModel
            import torch
            
            # ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ
            base_model = AutoModelForCausalLM.from_pretrained(
                "unsloth/gpt-oss-20b",
                torch_dtype=torch.float16,
                device_map="auto",
                trust_remote_code=True
            )
            
            # LoRA ì–´ëŒ‘í„° ë¡œë“œ
            model = PeftModel.from_pretrained(base_model, "{repo_name}")
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            tokenizer = AutoTokenizer.from_pretrained("{repo_name}")
            ```
            
            ### ì‚¬ìš© ì˜ˆì‹œ
            
            ```python
            messages = [
                {{"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ êµìœ¡ ë‚´ìš©ì„ ì„¤ëª…í•˜ëŠ” ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."}},
                {{"role": "user", "content": "2ì˜ ê±°ë“­ì œê³±ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."}}
            ]
            
            inputs = tokenizer.apply_chat_template(
                messages,
                add_generation_prompt=True,
                return_tensors="pt",
                return_dict=True
            ).to(model.device)
            
            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=512,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.9,
                    pad_token_id=tokenizer.eos_token_id
                )
            
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)
            print(response)
            ```
            
            ## ğŸ“Š í›ˆë ¨ ì •ë³´
            
            - **ë² ì´ìŠ¤ ëª¨ë¸**: unsloth/gpt-oss-20b-unsloth-bnb-4bit
            - **í›ˆë ¨ ìŠ¤í…**: 30 steps
            - **LoRA Rank**: 8
            - **LoRA Alpha**: 16
            - **íƒ€ê²Ÿ ëª¨ë“ˆ**: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj
            - **ë°ì´í„°ì…‹**: maywell/korean_textbooks
            
            ## ğŸ“ í™œìš© ë¶„ì•¼
            
            ì´ ëª¨ë¸ì€ ë‹¤ìŒ ë¶„ì•¼ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤:
            
            ### ìˆ˜í•™ (Mathematics)
            - ê¸°ì´ˆ ìˆ˜í•™ ê°œë… ì„¤ëª…
            - ëŒ€ìˆ˜, ê¸°í•˜, ë¯¸ì ë¶„ ë¬¸ì œ í•´ì„¤
            - ìˆ˜í•™ ê³µì‹ì˜ ì§ê´€ì  ì´í•´
            
            ### ê³¼í•™ (Science)
            - ë¬¼ë¦¬, í™”í•™, ìƒë¬¼í•™ ì›ë¦¬ ì„¤ëª…
            - ì‹¤í—˜ ê³¼ì • ë° ê²°ê³¼ í•´ì„
            - ê³¼í•™ì  í˜„ìƒì˜ ì´í•´
            
            ### ì–¸ì–´ (Language)
            - í•œêµ­ì–´ ë¬¸ë²• ë° ì–´íœ˜ ì„¤ëª…
            - ë¬¸í•™ ì‘í’ˆ ë¶„ì„ ë° í•´ì„
            - ê¸€ì“°ê¸° ê¸°ë²• ì•ˆë‚´
            
            ### ì‚¬íšŒ (Social Studies)
            - ì—­ì‚¬ì  ì‚¬ê±´ ë° ì¸ë¬¼ ì„¤ëª…
            - ì§€ë¦¬ì  ê°œë… ë° í˜„ìƒ
            - ì‚¬íšŒ ì œë„ ë° ë¬¸í™” ì´í•´
            
            ## ğŸ’» ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
            
            - **GPU ë©”ëª¨ë¦¬**: ìµœì†Œ 16GB (ê¶Œì¥ 24GB+)
            - **ì‹œìŠ¤í…œ RAM**: ìµœì†Œ 16GB
            - **Python**: 3.8+
            - **ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬**: transformers, peft, torch
            
            ## âš ï¸ ì£¼ì˜ì‚¬í•­
            
            1. **êµìœ¡ ëª©ì  íŠ¹í™”**: ì´ ëª¨ë¸ì€ êµìœ¡ ì½˜í…ì¸  ìƒì„±ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
            2. **í•œêµ­ì–´ ì¤‘ì‹¬**: í•œêµ­ì–´ ì™¸ì˜ ì–¸ì–´ì—ì„œëŠ” ì„±ëŠ¥ì´ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            3. **ì‚¬ì‹¤ í™•ì¸ í•„ìš”**: ìƒì„±ëœ ë‚´ìš©ì€ í•­ìƒ ê²€í† í•˜ê³  ì‚¬ì‹¤ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
            4. **ìœ¤ë¦¬ì  ì‚¬ìš©**: êµìœ¡ì ì´ê³  ê±´ì „í•œ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
            
            ## ğŸ”— ê´€ë ¨ ë§í¬
            
            - **ë² ì´ìŠ¤ ëª¨ë¸**: [unsloth/gpt-oss-20b](https://huggingface.co/unsloth/gpt-oss-20b)
            - **ë°ì´í„°ì…‹**: [maywell/korean_textbooks](https://huggingface.co/datasets/maywell/korean_textbooks)
            
            ## ğŸ“œ ë¼ì´ì„ ìŠ¤
            
            ì´ ëª¨ë¸ì€ ë² ì´ìŠ¤ ëª¨ë¸ì¸ unsloth/gpt-oss-20bì˜ ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
            """

        try:
            # README.md íŒŒì¼ ì €ì¥
            readme_path = os.path.join(model_path, "README.md")
            with open(readme_path, "w", encoding="utf-8") as f:
                f.write(readme_content)

            logger.info("ëª¨ë¸ì¹´ë“œ(README.md) ìƒì„± ì™„ë£Œ")
            print("âœ… ëª¨ë¸ì¹´ë“œ(README.md) ìƒì„± ì™„ë£Œ")
            
            return readme_path
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ì¹´ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def generate_model_card(self, model_path: str, repo_name: str, 
                          custom_description: Optional[str] = None) -> str:
        """
        ëª¨ë¸ì¹´ë“œ ìƒì„± (í™•ì¥ ê°€ëŠ¥í•œ ë²„ì „)
        
        Args:
            model_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
            repo_name: ë¦¬í¬ì§€í† ë¦¬ ì´ë¦„
            custom_description: ì‚¬ìš©ì ì •ì˜ ì„¤ëª…
            
        Returns:
            ìƒì„±ëœ README.md íŒŒì¼ ê²½ë¡œ
        """
        return self.create_model_card(model_path, repo_name)