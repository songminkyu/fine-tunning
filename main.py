"""
Main Execution Script
====================

í•œêµ­ì–´ êµìœ¡ìš© GPT-OSS ëª¨ë¸ íŒŒì¸íŠœë‹ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
ì›ë³¸ gpt-oss-kor-fine-tune.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ëª¨ë“ˆí™”í•˜ì—¬ ì¬êµ¬ì„±
"""

import logging
from core import (
    ModelConfig, ModelLoader, ModelInference, 
    DataProcessor, Trainer, ModelUploader
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("=" * 60)
    print("ğŸš€ í•œêµ­ì–´ êµìœ¡ìš© GPT-OSS ëª¨ë¸ íŒŒì¸íŠœë‹")
    print("=" * 60)
    
    try:
        # 1. ì„¤ì • ë¡œë”©
        logger.info("ì„¤ì • ì´ˆê¸°í™”")
        config = ModelConfig()
        print(f"ğŸ“‹ ì„¤ì • ë¡œë”© ì™„ë£Œ: {config.get_model_info()}")
        
        # 2. ëª¨ë¸ ë¡œë”© ë° ì„¤ì •
        logger.info("ëª¨ë¸ ë¡œë”© ì‹œì‘")
        model_loader = ModelLoader(config)
        model, tokenizer = model_loader.load_and_setup_model()
        print("âœ… ëª¨ë¸ ë¡œë”© ë° PEFT ì„¤ì • ì™„ë£Œ")
        
        # 3. ê¸°ë³¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸ (ì›ë³¸ ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸)
        logger.info("ê¸°ë³¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        inference = ModelInference(model, tokenizer, config)
        print("\nğŸ” ê¸°ë³¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸:")
        inference.test_basic_inference()
        
        # 4. ë°ì´í„°ì…‹ ë¡œë”© ë° ì²˜ë¦¬
        logger.info("ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‹œì‘")
        data_processor = DataProcessor(config)
        dataset = data_processor.load_dataset()
        print(f"âœ… ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ: {len(dataset)}ê°œ ìƒ˜í”Œ")
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì›ë³¸ printë¬¸ ì¬í˜„)
        print("\nğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        data_processor.preview_data(num_samples=1)
        
        # 5. í›ˆë ¨ ì¤€ë¹„ ë° ì‹¤í–‰
        logger.info("í›ˆë ¨ ì‹œì‘")
        trainer = Trainer(model, tokenizer, config)
        
        # í›ˆë ¨ ì„¤ì • ê²€ì¦
        if not trainer.validate_training_setup():
            print("âŒ í›ˆë ¨ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨")
            return False
        
        # ë°ì´í„°ì…‹ ì¤€ë¹„
        train_dataset = data_processor.prepare_for_training(tokenizer)
        
        # í›ˆë ¨ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í¬í•¨)
        print("\\nğŸ‹ï¸ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        trainer_stats = trainer.train(train_dataset)
        print("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        
        # 6. í›ˆë ¨ í›„ ì¶”ë¡  í…ŒìŠ¤íŠ¸ (ì›ë³¸ ë‘ ë²ˆì§¸ í…ŒìŠ¤íŠ¸)
        print("\\nğŸ” í•œêµ­ì–´ êµìœ¡ ì¶”ë¡  í…ŒìŠ¤íŠ¸:")
        inference.test_korean_inference()
        
        # 7. ëª¨ë¸ ì €ì¥
        model_path = trainer.save_model()
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
        
        # 8. ì—…ë¡œë“œ ì˜µì…˜ ì œê³µ (ì›ë³¸ ì‚¬ìš©ë²• ì•ˆë‚´)
        print("\\n" + "=" * 50)
        uploader = ModelUploader()
        uploader.print_usage_guide()
        
        # ì‹¤í–‰ ì„ íƒ (ì›ë³¸ ë¡œì§)
        choice = input("ì„ íƒí•˜ì„¸ìš” (1: ì €ì¥+ì—…ë¡œë“œ, 2: ì—…ë¡œë“œë§Œ, 3: ì¢…ë£Œ): ").strip()
        
        if choice == "1":
            print("\\nğŸ“¤ ëª¨ë¸ ì—…ë¡œë“œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
            success = uploader.save_and_upload_model(model, tokenizer)
            if success:
                print("ğŸ‰ ëª¨ë¸ ì—…ë¡œë“œ ì„±ê³µ!")
            else:
                print("âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨")
                
        elif choice == "2":
            print("\\nğŸ“¤ ê¸°ì¡´ ëª¨ë¸ ì—…ë¡œë“œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
            success = uploader.upload_existing_model()
            if success:
                print("ğŸ‰ ëª¨ë¸ ì—…ë¡œë“œ ì„±ê³µ!")
            else:
                print("âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨")
                
        elif choice == "3":
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        else:
            print("ì˜¬ë°”ë¥¸ ì„ íƒì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1, 2, ë˜ëŠ” 3)")
        
        print("\\n" + "=" * 60)
        print("ğŸ¯ í•œêµ­ì–´ êµìœ¡ìš© ëª¨ë¸ íŒŒì¸íŠœë‹ ì™„ë£Œ!")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        logger.error(f"ë©”ì¸ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def run_inference_only():
    """ì¶”ë¡ ë§Œ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜ (í›ˆë ¨ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ìš©)"""
    
    print("ğŸ” ì¶”ë¡  ì „ìš© ëª¨ë“œ")
    
    try:
        config = ModelConfig()
        
        # ì´ë¯¸ í›ˆë ¨ëœ ëª¨ë¸ì´ ìˆë‹¤ë©´ ë¡œë”©
        # ì´ ë¶€ë¶„ì€ ì‹¤ì œ ì‚¬ìš© ì‹œ ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”
        model_loader = ModelLoader(config)
        model, tokenizer = model_loader.load_and_setup_model()
        
        inference = ModelInference(model, tokenizer, config)
        
        print("\\nì „ì²´ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹¤í–‰:")
        inference.run_all_tests()
        
        return True
        
    except Exception as e:
        logger.error(f"ì¶”ë¡  ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"âŒ ì¶”ë¡  ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False


def run_upload_only():
    """ì—…ë¡œë“œë§Œ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    
    print("ğŸ“¤ ì—…ë¡œë“œ ì „ìš© ëª¨ë“œ")
    
    try:
        uploader = ModelUploader()
        uploader.print_usage_guide()
        
        success = uploader.upload_existing_model()
        
        if success:
            print("ğŸ‰ ëª¨ë¸ ì—…ë¡œë“œ ì„±ê³µ!")
        else:
            print("âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨")
            
        return success
        
    except Exception as e:
        logger.error(f"ì—…ë¡œë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"âŒ ì—…ë¡œë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    
    print("ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ì „ì²´ íŒŒì¸íŠœë‹ íŒŒì´í”„ë¼ì¸")
    print("2. ì¶”ë¡ ë§Œ ì‹¤í–‰")
    print("3. ì—…ë¡œë“œë§Œ ì‹¤í–‰")
    
    mode = input("ëª¨ë“œ ì„ íƒ (1/2/3): ").strip()
    
    if mode == "1":
        main()
    elif mode == "2":
        run_inference_only()
    elif mode == "3":
        run_upload_only()
    else:
        print("ì˜¬ë°”ë¥¸ ëª¨ë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš” (1, 2, ë˜ëŠ” 3)")